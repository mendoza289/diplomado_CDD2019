{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/jhermosillo/diplomado_CDD2019/blob/master/05%20Deep%20Learning/Notebooks/RNA_Keras_MNIST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"font-size:50px;\" align=\"left\"> <img align=\"left\" width=\"100%\" src=\"../img/data_science_rec.jpg\"/> <br> <br>Redes Neuronales con Keras y Tensorflow I</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<style>\n",
    "table, td, th {  \n",
    "  border: 1px solid #ddd;\n",
    "  text-align: left;\n",
    "}\n",
    "|  <img src=\"../img/data_science.jpg\" width=\"300\"/> |   <font color='midnightblue'>Diplomado en <br> Ciencia de Datos <br> con Python</font>|\n",
    "|:-:|:-|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#128214; <u>Referencias bibliográficas y sitios de interés</u>:\n",
    "* Ian Goodfellow, Yoshua Bengio, and Aaron Courville. 2016. Deep Learning. The MIT Press.\n",
    "* [Keras an API for Tensorflow](https://keras.io/getting_started/)\n",
    "* [Tensorflow: end-to-end open source machine learning platform](https://www.tensorflow.org/)\n",
    "* [Deep Learning with Keras and TensorFlow](https://www2.mpia-hd.mpg.de/homes/dgoulier/MLClasses/Course%20-%20Deep%20Learning%20with%20Keras%20and%20TensorFlow%20-%20Part%201.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# &#9991; <u> Introducción al diseño de RNA usando Keras</u>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"left\" width=\"100%\" src=\"../img/PROCESO_DEEP_LEARNING.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Módulos de Cómputo Científico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Módulos de RNA con Keras y TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensorflow y Keras\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "\n",
    "from keras.datasets import fashion_mnist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Conjunto de Datos de entrenamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST FASHION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a dataset of 60,000 28x28 grayscale images of 10 fashion categories, along with a test set of 10,000 images. This dataset can be used as a drop-in replacement for MNIST. The class labels are:\n",
    " <ul>\n",
    "  <li>0 T-shirt/top</li>\n",
    "  <li>1 Trouser</li>\n",
    "  <li>2 Pullover</li>\n",
    "  <li>3 Dress</li>\n",
    "  <li>4 Coat</li>\n",
    "  <li>5 Sandal</li>\n",
    "  <li>6 Shirt</li>\n",
    "  <li>7 Sneaker</li>\n",
    "  <li>8 Bag</li>\n",
    "  <li>9 Ankle boot</li>\n",
    "</ul> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prendas={0:'Camiseta',1:'Pantalones',2:'Suéter',3:'Vestido',4:'Abrigo',5:'Sandalia',6:'Camisa',7:'Sneaker',8:'Bolsa',9:'Botín'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separación en Entrenamiento, Validación y Prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()\n",
    "\n",
    "num_classes = 10\n",
    "X_train = X_train.reshape(60000, 784)\n",
    "X_test = X_test.reshape(10000, 784)\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "\n",
    "# One-hot vectors\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "# Reserva 10,000 muestras para validación\n",
    "X_val = X_train[-10000:]\n",
    "y_val = y_train[-10000:]\n",
    "X_train = X_train[:-10000]\n",
    "y_train = y_train[:-10000]\n",
    "\n",
    "print('Train size:', X_train.shape[0])\n",
    "print('Validation size:', X_val.shape[0])\n",
    "print('Test size:', X_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tamaño del conjunto de instancias\n",
    "m = y_train.shape[0]\n",
    "\n",
    "# indices de una permutación aleatoria de instancias \n",
    "# para visualizarlas\n",
    "indices = np.random.permutation(m)\n",
    "\n",
    "# Elegimos 100 puntos al azar para desplegar\n",
    "rand_indices = np.random.choice(m, 100, replace=False)\n",
    "sel = X_train[rand_indices, :].reshape((10,10,-1))\n",
    "\n",
    "# visualización de los datos\n",
    "fig, axarr = plt.subplots(10,10,figsize=(10,10))\n",
    "for i in range(10):\n",
    "    for j in range(10):\n",
    "        axarr[i,j].imshow(sel[i,j].reshape((28,28)), cmap='Greys')          \n",
    "        axarr[i,j].axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item=1692\n",
    "print(prendas[np.argmax(y_train[item])])\n",
    "fig,ax=plt.subplots(figsize=(1,1))\n",
    "ax.imshow(X_train[item].reshape((28,28)), cmap='Greys')\n",
    "ax.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train[:100]\n",
    "y_train = y_train[:100]\n",
    "X_val = X_val[:20]\n",
    "y_val = y_val[:20]\n",
    "\n",
    "X_test = X_test[:20]\n",
    "y_test = y_test[:20]\n",
    "\n",
    "print('Train size:', X_train.shape[0])\n",
    "print('Validation size:', X_val.shape[0])\n",
    "print('Test size:', X_test.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Arquitectura del Modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Librerías para diseño de modelos secuenciales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Librerías para el diseño de modelos secuenciales\n",
    "from keras.models import Sequential\n",
    "from keras.layers import InputLayer,Dense\n",
    "\n",
    "#librerías de visualización de grafos de cómputo\n",
    "import pydotplus\n",
    "import pydot\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "keras.utils.vis_utils.pydot = pydot\n",
    "\n",
    "# para evitar warnings...      \n",
    "import logging\n",
    "logging.getLogger('tensorflow').setLevel(logging.ERROR)\n",
    "\n",
    "from numpy.random import seed\n",
    "seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definición del modelo\n",
    "* La capa de entrada es de dimensión (400,)\n",
    "* Para comenzar definamos un modelo sencillo con una sola capa oculta\n",
    "* Una capa de salida con 10 neuronas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = Sequential()\n",
    "model1.add(InputLayer(input_shape=(X_train.shape[1],), name='Entrada'))\n",
    "model1.add(Dense(5,activation='sigmoid',name='Oculta'))\n",
    "model1.add(Dense(10, activation='sigmoid',name='Salida'))\n",
    "print(model1.summary())\n",
    "keras.utils.plot_model(model1,show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Configuración del aprendizaje"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizadores: Ref. https://ruder.io/optimizing-gradient-descent/index.html#fn12\n",
    "# - SGD: θ=θ−η⋅∇θJ(θ;x(i);y(i)).\n",
    "\n",
    "# - adagrad: gt,i=∇θJ(θt,i). θt+1=θt−η/√G+ϵ⋅g. G∈Rd×d here is a diagonal matrix \n",
    "#   where each diagonal element i,i is the sum of the squares of the gradients \n",
    "#   w.r.t. θi up to time step t.\n",
    "\n",
    "# - RMSprop: E[g^2](t)=0.9E[g^2](t−1)+0.1g^2 θt+1=θt−η√{E[g^2](t)+ϵ} g(t)\n",
    "#   RMSprop divides the learning rate by an exponentially decaying average \n",
    "#   of squared gradients. Hinton suggests γ to be set to 0.9, while a good \n",
    "#   default value for the learning rate η is 0.001.\n",
    "from keras.optimizers import SGD, RMSprop, adagrad\n",
    "\n",
    "EPOCAS = 5\n",
    "BATCH  = 16\n",
    "\n",
    "model1.compile(loss='binary_crossentropy',\n",
    "              optimizer=SGD(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Entrenamiento (iteración)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenamiento y evaluación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model1.fit(X_train, y_train,\n",
    "                    epochs=EPOCAS,\n",
    "                    batch_size=BATCH,\n",
    "                    validation_split=0.2, # alternativamente: validation_data=(X_val, y_val)\n",
    "                    verbose=1)\n",
    "\n",
    "print(model1.metrics_names)\n",
    "score = model1.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verificación visual del aprendizaje"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Curvas de pérdida (costo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print()\n",
    "print ('Test loss:', round(score[0], 3))\n",
    "print ('Test accuracy:', round(score[1]*100, 2))\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Curva de Error')\n",
    "plt.ylabel('error')\n",
    "plt.xlabel('epoca')\n",
    "plt.legend(['train', 'validation'], loc='upper right')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Curvas de exactitud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['accuracy'], label='train')\n",
    "plt.plot(history.history['val_accuracy'], label='test')\n",
    "plt.title('Curva de Exactitud')\n",
    "plt.ylabel('exactitud')\n",
    "plt.xlabel('epoca')\n",
    "plt.legend(['train', 'validation'], loc='lower right')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## &#9998; Ensaya distintas arquitecturas y configuraciones de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()\n",
    "\n",
    "num_classes = 10\n",
    "X_train = X_train.reshape(60000, 784)\n",
    "X_test = X_test.reshape(10000, 784)\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "\n",
    "# One-hot vectors\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "# Reserva 10,000 muestras para validación\n",
    "X_val = X_train[-10000:]\n",
    "y_val = y_train[-10000:]\n",
    "X_train = X_train[:-10000]\n",
    "y_train = y_train[:-10000]\n",
    "\n",
    "print('Train size:', X_train.shape[0])\n",
    "print('Validation size:', X_val.shape[0])\n",
    "print('Test size:', X_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense,Activation,Dropout\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.regularizers import l1,l1_l2,l2\n",
    "\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "\n",
    "from keras.optimizers import SGD, RMSprop, adagrad\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# Ejemplos de cómo agregar capas:\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(Dropout(0.2))\n",
    "# model.add(Dense(200,activation='tanh',\n",
    "#                 kernel_regularizer=l1_l2(l1=0.001,l2=0.0001),\n",
    "#                 bias_regularizer=l2(1e-4)\n",
    "#                 )\n",
    "#                 )\n",
    "# model.add(LeakyReLU(alpha=0.3))\n",
    "# model.add(Activation('relu'))\n",
    "\n",
    "\"\"\" TU CÓDIGO AQUÍ \"\"\"\n",
    "model.add(Dense(25,input_dim=X_train.shape[1]))\n",
    "model.add(Dense(10, activation='sigmoid'))\n",
    "\"\"\"------------------\"\"\"\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=SGD(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCAS = 5\n",
    "BATCH  = 10\n",
    "\n",
    "history = model.fit(X_train, y_train,\n",
    "                    epochs=EPOCAS,\n",
    "                    batch_size=BATCH,\n",
    "                    validation_split=0.2,\n",
    "                    verbose=0)\n",
    "\n",
    "print(model.metrics_names)\n",
    "score = model.evaluate(X_test, y_test)\n",
    "\n",
    "print()\n",
    "print ('Test loss:', round(score[0], 3))\n",
    "print ('Test accuracy:', round(score[1]*100, 2))\n",
    "plt.plot(history.history['loss'],label='train_loss')\n",
    "plt.plot(history.history['val_loss'],label='val_loss')\n",
    "plt.title('Curva de Error')\n",
    "plt.ylabel('error')\n",
    "plt.xlabel('epoca')\n",
    "plt.legend(['train', 'validation'], loc='upper left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exactitud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['accuracy'], label='train_acc')\n",
    "plt.plot(history.history['val_accuracy'], label='test_acc')\n",
    "plt.legend(bbox_to_anchor=(0.0, 0.0), loc='right', ncol=2)\n",
    "plt.title('Curva de Exactitud')\n",
    "plt.ylabel('exactitud')\n",
    "plt.xlabel('epoca')\n",
    "plt.legend(['train', 'validation'], loc='upper left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matriz de confusión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = model.predict(X_test)\n",
    "\n",
    "y_true = np.argmax(y_test, axis=1)\n",
    "y_pred = np.argmax(y_hat, axis=1)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "plt.imshow(conf_matrix, interpolation='nearest')\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.colorbar()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
