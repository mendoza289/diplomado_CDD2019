{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/jhermosillo/diplomado_CDD2019/blob/master/05%20Deep%20Learning/Notebooks/Propagacion_directa.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"font-size:50px;\" align=\"left\"> <img align=\"left\" width=\"30%\" src=\"../img/cerebro_1.jpg\"/>    \n",
    "    Redes Neuronales Artificiales - Propagación directa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from scipy import optimize\n",
    "from scipy.io import loadmat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Para subir carpetas a Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !apt-get install subversion\n",
    "# !svn checkout \"https://github.com/jhermosillo/diplomado_CDD2019/trunk/05%20Deep%20Learning/Data/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clasificación multiclase\n",
    "\n",
    "Para este ejercicio, usaremos una red neuronal para reconocer los dígitos escritos a mano (de 0 a 9). \n",
    "\n",
    "### Conjunto de datos\n",
    "\n",
    "* Se proporciona un conjunto de datos en `datosMNIST.mat` que contiene 5000 ejemplos de entrenamiento de dígitos escritos a mano (este es un subconjunto del conjunto de datos de dígitos escritos a mano [MNIST] (http://yann.lecun.com/exdb/mnist). El formato `.mat` significa que los datos se han guardado en un formato de matriz Octave / MATLAB nativo, en lugar de un formato de texto (ASCII) como un archivo csv. \n",
    "\n",
    "* Python proporciona mecanismos para cargar el formato nativo de MATLAB usando la función `loadmat` dentro del módulo` scipy.io`. Esta función devuelve un diccionario de Python con claves que contienen los nombres de las variables dentro del archivo `.mat`.\n",
    "\n",
    "* Hay 5000 ejemplos de entrenamiento en `datosMNIST.mat`, donde cada ejemplo de entrenamiento es una imagen del dígito en escala de grises de $20\\times 20$ píxeles. Cada píxel está representado por un número real que indica la intensidad de la escala de grises en esa ubicación. \n",
    "\n",
    "* La cuadrícula de pixeles de 20 por 20 se \"desenrolla\" en un vector de 400 dimensiones. Cada uno de estos ejemplos de capacitación se convierte en una sola fila en nuestra matriz de datos `X`. Esto nos da una matriz $X$ de 5000 por 400 donde cada fila es una instancia de entrenamiento para una imagen de dígitos escritos a mano.\n",
    "\n",
    "$$ X = \\begin{bmatrix} - \\: (x ^ {(1)})^T \\: - \\\\ - \\: (x ^{(2)})^ T \\: - \\\\ \\vdots \\\\ - \\: (x ^ {(m)})^ T \\: - \\end{bmatrix} $$\n",
    "\n",
    "* La segunda parte del conjunto de entrenamiento es un vector 'y' de 5000 dimensiones que contiene etiquetas para el conjunto de entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Datos de entrenamiento X, y\n",
    "data = loadmat('Data/datosMNIST')\n",
    "X, y = data['X'], data['y'].ravel()\n",
    "\n",
    "# Estos datos fueron creados en MATLAB donde no hay índice 0\n",
    "y[y == 10] = 0\n",
    "\n",
    "# tamaño del conjunto de instancias\n",
    "m = y.size\n",
    "\n",
    "# indices de una permutación aleatoria de instancias \n",
    "# para visualizarlas\n",
    "indices = np.random.permutation(m)\n",
    "\n",
    "# Elegimos 100 puntos al azar para desplegar\n",
    "rand_indices = np.random.choice(m, 100, replace=False)\n",
    "sel = X[rand_indices, :].reshape((10,10,-1))\n",
    "\n",
    "# visualización de los datos\n",
    "fig, axarr = plt.subplots(10,10,figsize=(10,10))\n",
    "for i in range(10):\n",
    "    for j in range(10):\n",
    "        axarr[i,j].imshow(sel[i,j].reshape((20,20), order = 'F'))          \n",
    "        axarr[i,j].axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1680\n",
    "print(y[1680])\n",
    "fig,ax=plt.subplots()\n",
    "ax.imshow(X[1680].reshape((20,20),order='F'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo de red neuronal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La red neuronal que vamos a implementar es la siguiente:\n",
    "\n",
    "<img align=\"left\" width=\"50%\" src=\"../img/redneuronal.jpg\"/> \n",
    "\n",
    "Tiene 3 capas: una capa de entrada, una capa oculta y una capa de salida. Recuerda que nuestras entradas son valores de pixeles de imágenes de dígitos. Dado que las imágenes tienen un tamaño de 20 × 20, esto nos da 400 neuronas de capa de entrada (excluyendo la neurona de polarización adicional que siempre genera +1). Como siempre, los datos de entrenamiento se cargarán en las variables $X$,$y$.\n",
    "\n",
    "Se te ha proporcionado un conjunto de parámetros de la red ($\\Theta^{(1)}$, $\\Theta^{(2)}$) ya entrenados. Estos están almacenados en `pesosFW.mat`. La siguiente celda carga esos parámetros en `Theta1` y` Theta2`. Los parámetros tienen dimensiones para una red neuronal con 25 neuronas en la segunda capa y 10 neuronas de salida (correspondientes a las clases de 10 dígitos)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parámetros para el ejercicio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parámetros\n",
    "neuronas_de_entrada  = 400  # Imágenes de entrada 20x20\n",
    "neuronas_ocultas = 25   # 25 neuronas coultas\n",
    "etiquetas = 10          # 10 etiquetas, clases de 0 a 9\n",
    "\n",
    "# Carga el archivo .mat que regresa un diccionario \n",
    "pesos = loadmat('Data/pesosFW.mat')\n",
    "\n",
    "# obtén los pesos del modelo del diccionario\n",
    "# Theta1 es una matriz de 25 x 401\n",
    "# Theta2 es una matriz de 10 x 26\n",
    "Theta1, Theta2 = pesos['Theta1'], pesos['Theta2']\n",
    "\n",
    "# intercambia la primera y última fila de Theta2, \n",
    "# debido a que los datos se originarion en MATLAB, con la indexación de MATLAB. \n",
    "Theta2 = np.roll(Theta2, 1, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Theta1.shape)\n",
    "print(Theta2.shape)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Propagación directa y predicción"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Completa el código en la función predicción para devolver la predicción de la red neuronal. \n",
    "* Debes implementar el cálculo directo de $h_{\\theta}(x^(i))$ para cada ejemplo $i$ y devolver las predicciones asociadas. \n",
    "* De acuerdo con la estrategia de clasificación de uno contra todos, la predicción de la red neuronal será la etiqueta que tenga el mayor valor $(h_{\\theta}(x^(i)))_k$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Función de activación sigmoide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoide(z):\n",
    "    return 1.0 / (1.0 + np.exp(-z))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### &#9998; Implementa la función `predict`\n",
    "\n",
    "<div class=\"alert alert-box alert-warning\">\n",
    "** Nota de implementación: ** La matriz $X$ contiene las instancias en cada fila. Cuando completes el código en la función $predict$, deberás agregar la columna de 1's a la matriz. Las matrices $Theta1$ y $Theta2$ contienen los parámetros para cada neurona en sus filas. Específicamente, la primera fila de $Theta1$ corresponde a los datos que van a ser procesados por la primera neurona oculta en la segunda capa. En $numpy$, cuando se calcula $z^{(2)}=\\Theta^{(1)}a^{(1)}$, hay que asegurarse de indexar (y si es necesario, transponer) $X$ correctamente para obtener $a^{(l)}$ como un vector 1-D.\n",
    "</div>\n",
    "<a id=\"predict\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(Theta1, Theta2, X):\n",
    "    \"\"\"\n",
    "    Predice la etiqueta de una entrada dada una red entrenada.\n",
    "    \n",
    "    Entradas:\n",
    "    ----------\n",
    "    Theta1 : tipo arreglo \n",
    "        Pesos para la capa 1 de la red neuronal.\n",
    "        Tiene shape (2da capa x capa de entrada)\n",
    "    \n",
    "    Theta2: tipo arreglo\n",
    "        Pesos para la capa 2 de la red neuronal.\n",
    "        Tiene shape (capa de salida x 2da capa)\n",
    "    \n",
    "    X : tipo arreglo (matriz)\n",
    "        Las imágenes de entrada de tamaño (instancias x dimensiones de laa imagen).\n",
    "    \n",
    "    Salidas: \n",
    "    ------\n",
    "    p : tipo arreglo\n",
    "        Vector de predicciones con etiquetas predichas para cada ejemplo\n",
    "        Su tamaño es igual al número de instancias.\n",
    "    \n",
    "    \"\"\"\n",
    "    # Necesitamos a X 2D\n",
    "    print(X.shape)\n",
    "    if X.ndim == 1:\n",
    "        X = X[None]\n",
    "    \n",
    "    # numero de instancias y etiquetas\n",
    "    m = X.shape[0]\n",
    "    etiquetas = Theta2.shape[0]\n",
    "\n",
    "    # Debes regresar el valor de estas variables correctamente \n",
    "    p = np.zeros(X.shape[0])\n",
    "\n",
    "    \"\"\" ====================== TU CODIGO AQUI ======================\n",
    "    TIP\n",
    "    ----\n",
    "    Este código se puede hacer todo vectorizado usando la función numpy argmax.\n",
    "    En particular, la función argmax devuelve el índice del elemento max.\n",
    "    Si tus instancias están en filas, entonces, puede usar np.argmax (A, axis = 1) \n",
    "    para obtener el índice del máximo para cada fila. Este índice correspondería al valor \n",
    "    de la clase a la que pertenece la instancia correspondiente.\n",
    "    \"\"\"\n",
    "    ones = np.ones((m,1))\n",
    "    a1 = np.hstack((ones,X))\n",
    "    z2 = a1@Theta1.T\n",
    "    a2 = sigmoide(z2)\n",
    "    a2 = np.hstack((ones,a2))\n",
    "    z3 = a2@Theta2.T\n",
    "    h = sigmoide(z3)\n",
    "    \n",
    "    p = np.argmax(h,axis=1)        \n",
    "    \"\"\" =============================================================\"\"\"\n",
    "    return p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prueba el modelo\n",
    "\n",
    "* Deberías ver una exactitud de aproximadamente 97.5%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = predict(Theta1, Theta2, X)\n",
    "np.mean(pred == y) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Para visualizar una por una las instancias de entrada y la predicción correspondiente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots(figsize=(4,4))\n",
    "if indices.size > 0:\n",
    "    i, indices = indices[0], indices[1:]\n",
    "    ax.imshow(X[i,:].reshape((20,20), order = 'F'))          \n",
    "    ax.axis('off')    \n",
    "    pred = predict(Theta1, Theta2, X[i, :])\n",
    "    print('Predición de la Red Neuronal: {}'.format(*pred))\n",
    "else:\n",
    "    print('No hay más imágenes.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
