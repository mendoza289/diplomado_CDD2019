{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/jhermosillo/Escuela_CD_IMATE_2019/blob/master/Wiki_PCA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|<img src=\"../img/AI_network.jpg\"  height=100 width=500/>|<font size=\"7\"><p style=\"text-align:left;\"><b>Diplomado en <br>Ciencia de Datos <br>con Python</b></p></font>|\n",
    "|-|-|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"font-size:50px;\" align=\"center\">Inferencia Probabilista y Enfoque Bayesiano en Reconocimiento de Patrones</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<style>\n",
    "table, td, th {  \n",
    "  border: 1px solid #ddd;\n",
    "  text-align: left;\n",
    "}\n",
    "|  <img src=\"../img/data_science.jpg\" width=\"300\"/> |   <font color='midnightblue'>Diplomado en <br> Ciencia de Datos <br> con Python</font>|\n",
    "|:-:|:-|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#128214; <u>Libro de referencia</u>:\n",
    "* Bishop, Christopher M. ( 2006). Pattern recognition and machine learning. New York. Springer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## &#9991; <u>I. Inferencia probabilista</u>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I.1. Ejemplo introductorio: Cajas con Frutas\n",
    "Supongamos que tenemos dos cajas, una caja roja que contiene 2 Manzanas y 6 Duraznos, y una caja azul que contiene 3 Manzanas y 1 Durazno.\n",
    "\n",
    "<img src=\"../img/peras_naranjas.png\" width=200/>\n",
    "\n",
    "Experimento(s):\n",
    "* <u>Elegimos una caja al azar</u> y <u>sacamos una fruta al azar</u>.\n",
    "* Habiendo observado qué fruta es, la volvemos a colocar en la caja de donde salió (muestreo con reemplazo).\n",
    "* Hacemos esto muchas veces; i.e. corremos el experimento varias veces (_trials_). \n",
    "\n",
    "Condiciones de partida (supuestos):\n",
    "* Supongamos que en este proceso tomamos la caja <b>roja 40%</b> de las veces y la caja <b>azúl 60%</b>.\n",
    "* Supongamos también que al devolver la fruta elegida al azar, cualquier otra fruta es igualmente probable de ser elegida la próxima vez (muestreo independiente)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Formalización matemática del Experimento y sus Resultados:\n",
    "\n",
    "#### Variable aleatoria, evento, distribución de probabilidad, valor de probabilidad\n",
    "* **La identidad de la caja** es una **_Variable Aleatoria_** (VA) que llamaremos $C$. Esta VA tiene **dos valores posibles**: $r$ (cuando se elige la caja roja) y $a$ (cuando elegimos la caja azúl).\n",
    "* La identidad de la fruta es una VA ($F$), cuyos valores posibles son $m$ y $d$.\n",
    "* Llamaremos un **_Evento_** el **resultado** de \"elegir una caja al azar\".\n",
    "* De esta forma, tenemos dos eventos posibles respecto de la primera parte del experimento: $C=r$ o $C=a$.\n",
    "* Llamaremos $P(C)$ la **distribución de probablidad** de $C$ y $p(C=x)$ el valor de probabilidad de que $C=x$. \n",
    "* Del ejemplo tenemos: $p(C=r)=4/10$ y $p(C=a)=6/10$; las respectivas proporciones de cada evento. Por definición los valores de probabilidad se encuentran en el intervalo $[0,1]$.\n",
    "* Para simplificar la notación escribiremos: $p(r)=0.4$ o $p(a)=0.6$.\n",
    "* Nota la diferencia entre el valor que puede tomar la VA ($r$ o $a$) y el valor de probabilidad de cada valor posible de la variable ($p(r)$ o $p(a)$).\n",
    "* Si los eventos son mutuamente excluyentes e incluyen todos los resultados posibles (como es el caso), entonces la suma de sus probabilidades es $1$: $p(r)+p(a)=1$.\n",
    "* A partir de aquí, nos podemos hacer varias preguntas. Por ejemplo, ¿Cuál es la probabilidad de elegir una Manzana? o ¿Dado que elegimos un Durazno, qué probablidad hay de que haya provenido de la caja azúl?\n",
    "* Para responder este tipo de preguntas, necesitamos utilizar las **_reglas de inferencia_** de la Teoría de Probabilidad."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  ### I.2. Regla del Producto y Regla de la Suma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Ilustración gráfica**.\n",
    "\n",
    "* Supongamos dos VA $X$ y $Y$. Supongamos además que $X$ tiene $i=1,\\ldots,M$ valores posibles y $Y$ tiene $j=1,\\ldots,L$ valores posibles, que denominaremos $x_i$ y $y_j$ respectivamente.\n",
    "* Supongamos que corremos el experimento $N$ veces (trials) y que en cada corrida muestreamos el valor de $X$ y de $Y$. \n",
    "* Sea $n_{ij}$ el **número de veces** en que $X=x_i$ y $Y=y_j$.\n",
    "* Sea $c_i$ el número de veces en que $X=x_i$ (independientemente de cuanto valga $Y$).\n",
    "* Sea $r_j$ el número de veces en que $Y=y_j$ (independientemente de cuanto valga $X$).\n",
    "\n",
    "<img src=\"../img/probas_graficas.jpg\" width=300/>\n",
    "<em><center>Ilustración de dos VA $X$ y $Y$: $X$ puede tomar 5 valores posibles y $Y$ 3. </center></em>\n",
    "\n",
    "<u>Probabilidad Conjunta</u>\n",
    "\n",
    "Es la probabilidad de que $X=x_i$ y $Y=y_j$ de manera simultánea (conjuntamente). Se escribe: $p(X=x_i,Y=y_j)$ y está dada por la proporción de veces en que ocurre esta conjunción (celda $(i,j)$) respecto del total de observaciones. \n",
    "\n",
    "<center>$p(x_i,y_j)=\\frac{n_{ij}}{N}$ &emsp;&emsp;&emsp;&emsp; (1)</center>\n",
    "\n",
    "<u>Probabilidad Marginal (Regla de la Suma)</u>\n",
    "\n",
    "Es la probabilidad de que $X=x_i$ de manera aislada (independientemente del valor de $Y$). Se escribe: $p(X=x_i)$ y está dada por la proporción del total de veces en que $X=x_i$ respecto del total de observaciones. \n",
    "\n",
    "<center>$p(x_i)=\\frac{c_{i}}{N}$ &emsp;&emsp;&emsp;&emsp; (2)</center>\n",
    "\n",
    "&#9758; Puesto que el número de instancias $c_i$ es el valor total de instancias en la columna $i$, tenemos que $c_i=\\sum n_{ij}$. Por lo tanto, de (1) y (2) tenemos:\n",
    "$$\n",
    "p(X=x_i)=\\sum_{j=1}^{L} p(X=x_i,Y=y_j) \\;\\;\\;\\;\\;\\;(3)\n",
    "$$\n",
    "\n",
    "<u>Probabilidad Condicional</u>\n",
    "\n",
    "Si consideramos sólo las instancias en que $X=x_i$, la fracción de estas instancias en las que $Y=y_j$ se escribe: $p(Y=y_j|X=x_i)$ y se le llama probabilidad condicional de $Y=y_j$ dado que $X=x_i$. Es la fracción de puntos que están en la columna $c_i$ que caen en la celda $(i,j)$: \n",
    "\n",
    "<center>$p(y_j|x_i)=\\frac{n_{ij}}{c_{i}}$ &emsp;&emsp;&emsp;&emsp; (4)</center>\n",
    "\n",
    "<u>Descomposición de la Conjunta (Regla del Producto)</u>\n",
    "\n",
    "&#9758; De (1), (2) y (4) tenemos la siguiente relación:\n",
    "\n",
    "$$\n",
    "p(X=x_i,Y=y_j) = \\frac{n_{ij}}{N} = \\frac{n_{ij}}{c_i}\\cdot\\frac{c_{i}}{N} = p(Y=y_j|X=x_i)p(X=x_i) \\;\\;\\;\\;\\;\\;(5)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Regla del Producto:**\n",
    "\n",
    "$$\n",
    "P(X,Y) = P(Y|X)P(X) \\;\\;\\;\\;\\;\\;(6)\n",
    "$$\n",
    "\n",
    "#### **Regla de la Suma:**\n",
    "\n",
    "$$\n",
    "p(X)=\\sum_{Y} P(X,Y) \\;\\;\\;\\;\\;\\;(7)\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9758; <u>NOTA</u>: Estas expresiones se refieren a distribuciones de probabilidad **discreta**. Debes tomar en cuenta que se trata de Tablas, donde se van llenando los valores de probabilidad para cada valor de $x_i$ y $y_j$. \n",
    "\n",
    "Para nuestro ejemplo de Cajas ($X$) y Frutas ($Y$), las Tablas de distribución tendrían una aspecto similar a estos:\n",
    "<table width=\"90%\">\n",
    "    <tr>\n",
    "        <td valign=\"top\">\n",
    "            <table width=\"40%\">\n",
    "              <tr>\n",
    "                <th> $X$</th>\n",
    "                <th><p style=\"text-align:center;\"> $P(X)$</p></th>\n",
    "              </tr>\n",
    "              <tr>\n",
    "                <td><p style=\"text-align:center;\">$r$</p></td>\n",
    "                <td><p style=\"text-align:center;\">$p(r)$</p></td>\n",
    "              </tr>\n",
    "              <tr>\n",
    "                <td><p style=\"text-align:center;\">$a$</p></td>\n",
    "                <td><p style=\"text-align:center;\">$p(a)$</p></td>\n",
    "              </tr>\n",
    "            </table>\n",
    "        </td>\n",
    "        <td valign=\"top\">\n",
    "            <table >\n",
    "              <tr>\n",
    "                <th> $X, Y$</th>\n",
    "                <th><p style=\"text-align:center;\"> $P(X,Y)$</p></th>\n",
    "              </tr>\n",
    "              <tr>\n",
    "                <td><p style=\"text-align:center;\">$r,m$</p></td>\n",
    "                <td><p style=\"text-align:center;\">$p(r,m)$</p></td>\n",
    "              </tr>\n",
    "              <tr>\n",
    "                <td><p style=\"text-align:center;\">$r,d$</p></td>\n",
    "                <td><p style=\"text-align:center;\">$p(r,d)$</p></td>\n",
    "              </tr>\n",
    "              <tr>\n",
    "                <td><p style=\"text-align:center;\">$a,m$</p></td>\n",
    "                <td><p style=\"text-align:center;\">$p(a,m)$</p></td>\n",
    "              </tr>\n",
    "              <tr>\n",
    "                <td><p style=\"text-align:center;\">$a,d$</p></td>\n",
    "                <td><p style=\"text-align:center;\">$p(a,d)$</p></td>\n",
    "              </tr>\n",
    "            </table>\n",
    "        </td>\n",
    "        <td valign=\"top\">\n",
    "            <table >\n",
    "              <tr>\n",
    "                <td style=\"height:1px;\"> &nbsp;</td>\n",
    "                <td colspan=\"2\"><p style=\"text-align:center;\">$P$($Y$|$X$)</p></td>\n",
    "              </tr>\n",
    "              <tr>\n",
    "                <td>$X$</td>\n",
    "                <td><p style=\"text-align:center;\">$m$</p></td>\n",
    "                <td><p style=\"text-align:center;\">$d$</p></td>\n",
    "              </tr>\n",
    "              <tr>\n",
    "                <td><p style=\"text-align:center;\">$r$</p></td>\n",
    "                <td><p style=\"text-align:center;\">$p(m|r)$</p></td>\n",
    "                <td><p style=\"text-align:center;\">$p(d|r)$</p></td>\n",
    "              </tr>\n",
    "              <tr>\n",
    "                <td><p style=\"text-align:center;\">$a$</p></td>\n",
    "                <td><p style=\"text-align:center;\">$p(m|a)$</p></td>\n",
    "                <td><p style=\"text-align:center;\">$p(d|a)$</p></td>\n",
    "              </tr>\n",
    "            </table>        \n",
    "        </td>\n",
    "    </tr>\n",
    "</table>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I.3. Teorema de Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De la regla del producto podemos observar que:\n",
    "\n",
    "$$\n",
    "P(X,Y) = P(Y|X)P(X) = P(X|Y)P(Y) \\;\\;\\;\\;\\;\\;(8)\n",
    "$$\n",
    "\n",
    "Despejando para $P(Y|X)$ tenemos el **Teorema de Bayes**:\n",
    "\n",
    "$$\n",
    "P(Y|X) = \\frac{P(X|Y)P(Y)}{P(X)} \\;\\;\\;\\;\\;\\;(9)\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### &#9998; Ejercicios-Reglas de la Inferencia Probabilista"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aplicando las ecuaciones (6) a (9) responde a las siguientes preguntas para nuestro ejemplo de Manzanas y Duraznos:\n",
    "\n",
    "<ol>\n",
    "    <li>¿Cuál es la probabilidad de elegir una Manzana?</li>\n",
    "    <li>¿Dado que elegimos un Durazno, qué probablidad hay de que haya provenido de la caja azúl?</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9758; Representemos $P(X)$, la distribución de X (el color de la caja)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p(X=r) = 0.4; p(X=a) = 0.6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>P(X)</th>\n",
       "      <th>p</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>r</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>a</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "P(X)    p\n",
       "X        \n",
       "r     0.4\n",
       "a     0.6"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#PX={'r':4/10, 'a':6/10}. los datos:\n",
    "data={'p':[4/10,6/10]}\n",
    "\n",
    "#construimos el DF\n",
    "PX=pd.DataFrame(data,index=['r','a'])\n",
    "\n",
    "#Cambiamos el titulo del indice\n",
    "PX.index.names = ['X']\n",
    "PX.columns.names = ['P(X)']\n",
    "\n",
    "print('p(X=r) = {0}; p(X=a) = {1}'.format(PX['p']['r'],PX['p']['a']))\n",
    "PX\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9998; Calcula $P(Y|X)$ (PY_X). ¿Qué representa esta distribución para nuestro ejemplo?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>P(Y|X)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>r</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: [r, a]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TIP: de los datos de partida, encuentra:\n",
    "# pm_r,pm_a\n",
    "# pd_r,pd_a\n",
    "\n",
    "#luego construye el diccionario 'data'\n",
    "data={}\n",
    "\n",
    "#construimos el DF\n",
    "PY_X=pd.DataFrame(data,index=[\"r\", \"a\"])\n",
    "PY_X.index.names = ['X']\n",
    "PY_X.columns.names = ['P(Y|X)']\n",
    "PY_X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "&#9998; ¿Cuál es la probabilidad de elegir una Manzana?\n",
    "\n",
    "* ¿Cómo se representa la probabilidad de esta pregunta?\n",
    "* Calcúlala\n",
    "* Proporciona la distribución completa $P(Y)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "&#9998; ¿Dado que elegimos un Durazno, qué probablidad hay de que haya provenido de la caja azúl?\n",
    "\n",
    "* ¿Cómo se representa la probabilidad de esta pregunta? \n",
    "* Calcúlala\n",
    "* Proporciona la distribución completa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  I.4 Inferencia Continua"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el caso de VA continuas, el cálculo de probabilidades pasa por la integración de la función de **densidad de probabilidad**. Por ejemplo, si $x$ es una VA continua, que toma valores en el intervalo $(a,b)$, y si su función de densidad probabilidad es $f(x)$, entonces:\n",
    "\n",
    "$$\n",
    "p(x\\in(a,b))=\\int_a^b f(x)\\,\\textrm{d}x\n",
    "$$\n",
    "\n",
    "$$\n",
    "p(x) \\geq 0\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\int_{-\\infty}^{\\infty} f(x)\\,\\textrm{d}x = 1\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../img/densidad_probabilidad.png\" width=\"50%\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si tenemos dos VA continuas $x$ y $y$ y funciones de densidad de probabilidad marginal $p(x)$, conjunta $p(x,y)$ y condicional $p(y|x)$, las reglas del producto y de la suma tiene la misma forma que vimos antes:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Regla del Producto:**\n",
    "\n",
    "$$\n",
    "p(x,y) = p(y|x)p(x) \\;\\;\\;\\;\\;\\;(10)\n",
    "$$\n",
    "\n",
    "#### **Regla de la Suma:**\n",
    "\n",
    "$$\n",
    "p(x)=\\int p(x,y)\\,\\textrm{d}y \\;\\;\\;\\;\\;\\;(11)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## &#9991; <u>II. Enfoque Bayesiano: inferencia con incertidumbre</u>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* El ejemplo anterior, es un clásico ejemplo de cómo se utilizan las reglas de inferencia probabilista, bajo un **enfoque frecuentista**. \n",
    "* En algunas ocasiones es prácticamente imposible realizar un conteo de ciertos fenómenos o situaciones reales. Pensemos en la situación actual de la pandemia covid19. ¿Habrá desaparecido el riesgo de contagio en México en el 2021? Esta es una pregunta sobre la que no tenemos forma de repetir experimentos y calcular una probabilidad en la misma forma que en el ejemplo de las frutas. \n",
    "* Aún así, es posible tener una estimación de la velocidad de contagio y de la disminución del número de personas infectadas hasta ahora. Con ello, podríamos hacernos una idea (**una creencia** o **hipótesis**) sobre la respuesta a la pregunta.\n",
    "* Esta  **creencia a priori**, sin embargo, tendría que **modificarse** conforme vayamos teniendo **nueva evidencia**¨sobre el comportamiento de los contagios.\n",
    "* La evaluación de estos aspectos nos llevaría a **tomar decisiones**, cuyos efectos deberíamos ser capaces de observar para validar nuestras hipótesis.  \n",
    "* Ante estas circunstancias, es deseable tener una forma de **medir la incertidumbre** alrededor de nuestras hipótesis, y hacer revisiones de esta incertidumbre a la luz de nueva información.\n",
    "* Esto se logra gracias a la elegante interpretación de la probabilidad bayesiana."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#128214; <u>Orígenes del bayesianismo</u>:\n",
    "<br>\n",
    "<ul>\n",
    "    <li> Biografía de <a href=\"https://es.wikipedia.org/wiki/Thomas_Bayes\"> Thomas Bayes</a> en Wikipedia</li>\n",
    "    <li> <a href=\"https://en.wikipedia.org/wiki/Cox%27s_theorem\"> Cox's Theorem</a> en Wikipedia</li>\n",
    "    <li> Cox, R. T. (1946). \"Probability, Frequency and Reasonable Expectation\". American Journal of Physics. 14: 1–10. doi:<a href=\"https://aapt.scitation.org/doi/10.1119/1.1990764\">10.1119/1.1990764</a>. </li>\n",
    "    <li>Cox, R. T. (1961). The Algebra of Probable Inference. Baltimore, MD: Johns Hopkins University Press. </li>\n",
    "    <li>Jaynes, E.T. (2003). Probability Theory - The Logic of Science.  Cambridge University Press. doi: <a href=\"https://www.cambridge.org/core/books/probability-theory/9CA08E224FF30123304E6D8935CF1A99\">10.1017/CBO9780511790423</a></li>\n",
    "</ul>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### II.1. Re-interpretación del Teorema de Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../img/enfoque_bayesiano.png\" width=\"80%\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### II.2. El problema de Clasificación desde la perspectiva Bayesiana"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Supongamos que tenemos un vector de datos de entrada $\\textrm{x}$, junto con un vector objetivo correspondiente $\\textrm{t}$.\n",
    "* __Regresión__: $\\textrm{t}$ es un vector de valores numéricos reales.\n",
    "* __Clasificación__: $\\textrm{t}$ es un vector de clases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* La probabilidad conjunta $p(\\textrm{x}, \\textrm{t})$ contiene toda la información respecto de estas variables y **describe la incertidumbre** asociada a ellas.\n",
    "* Determinar $p(\\textrm{x}, \\textrm{t})$ de un conjunto de **datos de entrenamiento** es un ejemplo de inferencia, y en general un problema muy difícil.\n",
    "* En situaciones prácticas, debemos hacer una **predicción** respecto del valor de $\\textrm{t}$, o tener una idea de su valor con el fin de **tomar una decisión**. \n",
    "* Generalmente la decisión consiste, en el caso de la **Clasificación**, en **asignar un nuevo dato a una de las clases**, y en el caso de la **Regresión**, **hacer corresponder a una nueva variable de entrada el valor numérico \"óptimo\"**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9758; Desde un enfoque Bayesiano, el problema de **_Clasificación_** se puede describir de la siguiente forma:\n",
    "\n",
    "$$\n",
    "p(\\mathcal{C}_k|\\textrm{x}) = \\frac{p(\\textrm{x}|\\mathcal{C}_k)p(\\mathcal{C}_k)}{p(\\textrm{x})}\\;\\;\\;\\;\\;\\;\\;(12)\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* El problema de la decisión puede resolverse de tres maneras posibles:\n",
    "<ol>\n",
    "    <li> Primero resuelve el problema de inferencia de determinar las distribuciones de probabilidad condicional a las clases $p(\\textrm{x}|\\mathcal{C}_k)$ para cada clase $\\mathcal{C}_k$ individualmente. Además, infiere las probabilidades sobre el <i>a-priori</i> de cada clase $p(\\mathcal{C}_k)$. Luego, usa el teorema de Bayes (12) para encontrar los <i>a-posterioris</i> $p(\\mathcal{C}_k|\\textrm{x})$. Como es habitual, el denominador puede calcularse de la siguiente forma:<br>&nbsp;\n",
    "        $$\n",
    "        p(\\textrm{x}) = \\sum_k p(\\textrm{x}|\\mathcal{C}_k)p(\\mathcal{C}_k)\\;\\;\\;\\;\\;\\;\\;(13)\n",
    "        $$     \n",
    "        Habiendo encontrado las distribuciones <i>a-posteriori</i>, usa el criterio de <b>MAP</b> (<i>Máximo A Posteriori</i>) para asignar cada nuevo $\\textrm{x}$ a una de las clases. Los enfoques que explícita o implícitamente modelan las distribuciones de entradas y salidas se llaman <b><i>modelos generativos</i></b>, ya que se pueden generar datos sintéticos muestreándolos. <br> &#9758; P.Ej. <i>Naïve Bayes</i></li>\n",
    "    <li> Primero resuelve el problema de inferencia de las distribuciones <i>a-posteriori</i> $p(\\mathcal{C}_k|\\textrm{x})$, y después usa el criterio de MAP para asignar cada nuevo $\\textrm{x}$ a una de las clases. Los enfoques que modelan directamente las distribuciones <i>a-posteriori</i> se llaman  <b><i>modelos discriminativos</i></b> <br> &#9758; P.Ej. <i>Regresión Logística</i></li>\n",
    "    <li> Encuentra una función $f(\\textrm{x})$, llamada <b><i>función discriminante</i></b>, que mapea cada entrada $\\textrm{x}$ directamente a una clase. Por ejemplo, en el caso de la clasificación binaria, $f=0$ representa la clase $\\mathcal{C}_1$ y $f=1$ la clase $\\mathcal{C}_2$. En este caso, las probabilidades no se utilizan. <br> &#9758; P.Ej. <i>SVM</i> o <i>RRNN.</i></li>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### II.3. La Clasificación como la estimación de una densidad de probabilidad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* El párrafo anterior plantea la necesidad modelar los datos como distribuciones de probabilidad $p(\\textrm{x})$, dado un conjunto de observaciones $\\textrm{x}_1,\\ldots,\\textrm{x}_N$.\n",
    "* Un enfoque ampliamente difundido es el de usar distribuciones paramétricas: p.ej. Binomial o Gaussiana.\n",
    "* Un supuesto importante es considerar que los datos son independientes e idénticamente distribuidos (_iid_).\n",
    "* En principio, existe un número infinito de posibilidades para elegir una distribución $\\implies$ problema de selección del modelo.\n",
    "* En este curso vamos a utilizar distribuciones parámetricas, ya que están gobernadas por un número pequeño de parámetros y se utilizan muy ampliamente en la literatura.\n",
    "* Para ajustar los parámetros de estos modelos, vamos a seguir dos principios: el de **Máximo de Verosimilitud** (frecuentista) o el **Bayesiano** (calcular el a posteriori, partiendo de un a prioir, conforme se observan datos)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../img/ajuste_bayesiano.png\" width=\"100%\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### II.3.1 El Máximo de Verosimilitud (_Maximum Likelihood_) como criterio de ajuste de un modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### La distribución Gaussiana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rc('text', usetex=True)\n",
    "\n",
    "colores = {'dr':'darkred','fb':'firebrick','ir':'indianred','or':'orangered',\n",
    "           'lc':'lightcoral','do':'darkorange','gr':'goldenrod','od':'olivedrab',\n",
    "           'fg':'forestgreen','l':'lime','t':'teal','bv':'blueviolet','dv':'darkviolet',\n",
    "           'oc':'orchid','dp':'deeppink','b':'blue','g':'green','r':'r'}\n",
    "\n",
    "def CurvaGaussiana(mu,s,muestras=1000):\n",
    "    x = np.linspace(-100,100,muestras)\n",
    "    y = 1/(s * np.sqrt(2 * np.pi)) * np.exp( - (x - mu)**2 / (2 * s**2))\n",
    "    return x,y\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6, 4), tight_layout=True)\n",
    "\n",
    "mu=0.0\n",
    "s=1.0\n",
    "x,y=CurvaGaussiana(mu,s)\n",
    "\n",
    "ax.axis([-3,3,0,0.45])\n",
    "ax.plot(x, y,\n",
    "        lw=2, \n",
    "        color=colores['fb'],\n",
    "        ls='-',\n",
    "       label=r'$\\displaystyle p(x)=\\mathcal{N}(x|\\mu,\\sigma^2)=\\frac{1}{2\\pi\\sigma^2}\\exp\\left\\{-\\frac{1}{2\\sigma^2}(x-\\mu)^2\\right\\}$')\n",
    "ax.set_xlabel(r'$x$', fontsize=16)\n",
    "ax.set_title(r'Distribución Gaussiana', fontsize=16, color='b')\n",
    "plt.legend(fontsize=16,loc=1,frameon=False,bbox_to_anchor=(1.5,-0.25))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La Gaussiana uni-dimensional:\n",
    "$$\n",
    "\\displaystyle p(x|\\mu,\\sigma^2)=\\mathcal{N}(x|\\mu,\\sigma^2)=\\frac{1}{2\\pi\\sigma^2}\\exp\\left\\{-\\frac{1}{2\\sigma^2}(x-\\mu)^2\\right\\}\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;(14)\n",
    "$$\n",
    "\n",
    "La Gaussiana multidimensional:\n",
    "$$\n",
    "\\displaystyle p(\\textrm{x}|\\mathbf{\\mu},\\Sigma)=\\mathcal{N}(\\textrm{x}|\\mathbf{\\mu},\\Sigma)=\\frac{1}{(2\\pi)^{D/2}|\\Sigma|^{1/2}}\\exp\\left\\{-\\frac{1}{2}(\\textrm{x}-\\mu)^\\textrm{T}\\Sigma^{-1}(\\textrm{x}-\\mu)\\right\\}\\;\\;\\;\\;\\;\\;(15)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Supongamos que tenemos datos uni-dimensionales, cuyo origen desconocemos... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.39 1.56 0.96 1.83 0.89 2.16 1.16 1.19 1.29 1.46]\n"
     ]
    }
   ],
   "source": [
    "def datos_misteriosos(n):\n",
    "    x_= np.round(np.random.normal(1.5,0.5,n),2)\n",
    "    for x in x_:\n",
    "        yield x\n",
    "\n",
    "#10 observaciones  \n",
    "X=datos_misteriosos(10)\n",
    "D=[]\n",
    "\n",
    "for x in X:\n",
    "    D.append(x)\n",
    "D=np.array(D)\n",
    "print(D)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* El objetivo es estimar los parámetros de su distribución, suponiendo que tienen una distribución Gaussiana.\n",
    "* Para ello vamos a maximizar la función de verosimilitud (likelyhood), para N observaciones:\n",
    "\n",
    "$$\n",
    "\\displaystyle p(\\textrm{x}|\\mu,\\sigma^2)=\\prod_{n=1}^{N}\\mathcal{N}(x_n|\\mu,\\sigma^2)\\;\\;\\;\\;\\;\\;\\;\\;(16)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* En estos casos es común calcular el $\\log$(likelyhood):\n",
    "\n",
    "$$\n",
    "\\displaystyle \\ln p(\\textrm{x}|\\mu,\\sigma^2)=-\\frac{1}{2\\sigma^2}\\sum_{n=1}^N(x_n-\\mu)^2 -\\frac{N}{2}\\ln \\sigma^2 -\\frac{N}{2}\\ln (2\\pi)\\;\\;\\;\\;\\;\\;\\;\\;(17)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9758; Maximizando (17) con respecto a $\\mu$, obtenemos:\n",
    "\n",
    "$$\n",
    "\\displaystyle \\mu_{ML}= \\frac{1}{N}\\sum_{n=1}^N x_n \\;\\;\\;\\;\\;\\;\\;\\;(18)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9758; Maximizando (17) con respecto a $\\sigma^2$, obtenemos:\n",
    "\n",
    "$$\n",
    "\\displaystyle \\sigma^2_{ML}= \\frac{1}{N}\\sum_{n=1}^N (x_n-\\mu_{ML})^2 \\;\\;\\;\\;\\;\\;\\;\\;(19)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#9998; Define una función que estime calcule los parámetros $\\mu_{ML}$ y $\\sigma^2$ para nuestros datos $D$. Compara estos cálculos contra los que te da numpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
