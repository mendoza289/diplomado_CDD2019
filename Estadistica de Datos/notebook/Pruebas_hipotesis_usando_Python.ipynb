{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/jhermosillo/diplomado_CDD2019/blob/master/Estadistica%20de%20Datos/notebook/Pruebas_hipotesis_parametricas_no-parametricas.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.9. Pruebas de hipótesis usando Python\n",
    "---\n",
    "![alt text](https://www.monografias.com/trabajos91/prueba-hipotesis-medias-excel-y-winstats/image002.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bueno, probablemente todos los que somos principiantes o en nivel intermedi en ciencia de datos o los estudiantes de estadística escucharon sobre estas palabras de moda en estas áreas y esto es las prueba de hipótesis.\n",
    "\n",
    "En esta sección se dará una breve introducción sobre este tema que puede causar muchos dolores de cabeza al estar aprendiendo acerca del manejo de datos.\n",
    "\n",
    "Se abordan todos esos conceptos y con ejemplos usando Python.\n",
    "\n",
    "* # ¿Qué es una prueba de hipótesis? \n",
    "* ## ¿Porqué debemos usarlas? \n",
    "* ## ¿Cuáles son las bases de las hipótesis?\n",
    "* ## ¿Cuáles son los parámetros importantes de dichas pruebas?\n",
    "\n",
    "\n",
    "![alt text](https://luminousmen.com/media/demystifying-hypothesis-testing.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Empecemos por la primera pregunta...\n",
    "\n",
    "* ## ¿Qué es una prueba de hipótesis?\n",
    "\n",
    "Las pruebas de hipótesis son métodos estadísticos que son utilizados para la toma de decisiones **estadísticas**, utilizando datos experimentales. En palabras burdas, es el pan de cada día de las estadísticas inferenciales y una habilidad crítica en el repertorio de un científico de datos. Demostramos el concepto con scripts Python muy simples.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ## ¿Porqué usamos las pruebas de hipótesis?\n",
    "\n",
    "La prueba de hipótesis es un procedimiento esencial en estadística. Una prueba de hipótesis evalúa dos afirmaciones mutuamente excluyentes sobre una **población** para determinar qué afirmación es mejor respaldada por los datos de la *muestra*. Cuando decimos que un hallazgo es estadísticamente significativo, es gracias a una prueba de hipótesis.\n",
    "\n",
    "### La prueba de hipótesis es una herramienta crítica en estadística inferencial, para determinar cuál podría ser el valor de un parámetro de **población**. A menudo sacamos esta conclusión basada en un análisis de datos de muestra...."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con la cuestión de la toma de decisiones basada en datos:\n",
    "\n",
    "   * empresariales, científicos, tecnológicos, sociales y políticos, etc... \n",
    "    \n",
    "El concepto de prueba de hipótesis se ha convertido en algo sumamente importante para comprender y aplicar en el contexto adecuado.\n",
    "\n",
    "#### Hay una gran cantidad de pruebas utilizadas en el análisis estadístico para este propósito. Puede ser confuso. Consulte este excelente [artículo](https://towardsdatascience.com/statistical-tests-when-to-use-which-704557554740) para obtener una descripción completa de qué prueba usar en qué situación."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ## ¿Cuales son las bases de las hipótesis? \n",
    "\n",
    "   * Hipótesis Nula\n",
    "   * Hipótesis Alterna\n",
    "   \n",
    "La hipótesis nula es, en general, lo **aburrido** (esperado), es decir, supone que nada interesante sucede / sucedió.\n",
    "\n",
    "La hipótesis alterna es donde la acción es, es decir, alguna observación / fenómeno es real (es decir, no es una casualidad)...\n",
    "\n",
    "---\n",
    "\n",
    "Hipótesis nula (H0): - En la estadística inferencial, la hipótesis nula es una declaración general o posición predeterminada de que no hay relación entre dos fenómenos medidos, o no hay asociación entre grupos\n",
    "\n",
    "En otras palabras, es una suposición básica o basada en el dominio o el conocimiento del problema.\n",
    "\n",
    "Ejemplo: la producción de una empresa es = 50 unidades / por día, etc.\n",
    "\n",
    "---\n",
    "\n",
    "Hipótesis alterna (H1): - Es la hipótesis contraria a la hipótesis nula. Por lo general, se considera que las observaciones son el resultado de un efecto real (con cierta cantidad de variación de probabilidad superpuesta)\n",
    "\n",
    "Ejemplo: la producción de una empresa es ! = 50 unidades / por día, etc.\n",
    "\n",
    "---\n",
    "## Por lo tanto, el proceso de prueba de hipótesis consiste en formular preguntas sobre los datos en función de la información recopilada y probarlas utilizando métodos estadísticos.\n",
    "\n",
    "---\n",
    "### A continuación mostramos un pequeño ejemplo utilizando la prueba estadística Shapiro - Wilks\n",
    "Esta prueba comprueba si una muestra presenta una distribución normal(H0) o no (H1). Mayor información de la librería pueden consultar el siguiente [artículo](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.shapiro.html) y el [artículo](https://en.wikipedia.org/wiki/Shapiro%E2%80%93Wilk_test) siguiente para la prueba estadística. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of the Shapiro-Wilk Normality Test\n",
    "from scipy.stats import shapiro\n",
    "import seaborn as sns\n",
    "data = [0.873, 2.817, 0.121, -0.945, -0.055, -1.436, 0.360, -1.478, -1.637, -1.869]\n",
    "stat, p = shapiro(data)\n",
    "print('stat=%.3f, p=%.3f' % (stat, p))\n",
    "if p > 0.05:\n",
    "    print('Probably Gaussian')\n",
    "else:\n",
    "    print('Probably not Gaussian')\n",
    "    \n",
    "sns.distplot(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilizando random para genera números aleatorios.\n",
    "import numpy as np # importando numpy\n",
    "\n",
    "np.random.seed(1984) # para poder replicar el random\n",
    "from scipy import stats\n",
    "\n",
    "muestras = np.random.normal(0, 1, 1000)\n",
    "\n",
    "#muestras = np.random.beta(2, 4, 1000)\n",
    "muestras\n",
    "\n",
    "stat, p = shapiro(muestras)\n",
    "print('stat=%.3f, p=%.3f' % (stat, p))\n",
    "alpha = 0.5\n",
    "if p > alpha:\n",
    "    print('Sample looks Gaussian (fail to reject H0)')\n",
    "else:\n",
    "    print('Sample does not look Gaussian (reject H0)')\n",
    "    \n",
    "sns.distplot(muestras)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A partir de aquí surgen diversas cuestiones extrañas...\n",
    "\n",
    "### ¿Qué son las pruebas estadísticas?\n",
    "* ### ¿Qué es el valor de la prueba (estadística)? \n",
    "\n",
    "    * #### $\\alpha$ (nivel de significancia) \n",
    "    * #### $(p - value)$ \n",
    "    * #### [valor crítico](https://scistatcalc.blogspot.com/2013/09/critical-value-of-w-statistic.html?m=0)\n",
    "    \n",
    "    \n",
    "![alt text](https://iamluminousmen-media.s3.amazonaws.com/media/demystifying-hypothesis-testing/demystifying-hypothesis-testing-3.jpg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ¿Cuál es el proceso?\n",
    "\n",
    "Normalmente empezamos con un punto de vista simple y empezamos con al hipótesis nula y calculamos (computamos) algunos estadísticos con respecto a nuestras muestras, que se puediera sintetizar de la siguiente manera:\n",
    "\n",
    "## $\\displaystyle\\frac{Mejor estimación − Estimación Hipotética}{Error estandar Estimación}$\n",
    "\n",
    "Donde, la **mejor estimación** proviene de la muestra.. p.ej., la media o algun valor de tendencia central de algún subconjunto de datos de la muestra.\n",
    "\n",
    "El **error estandar** representa la variabilidad en la estimación y depende de la varianza y del tamaño de la muestra.\n",
    "\n",
    "A lo que nos lleva a la siguiente pregunta...\n",
    "\n",
    "### \"¿Cuál es la posibilidad de observar el estadístico de prueba, este extremo, para esta muestra (considerando su tamaño y una dinámica probabilística adecuada que la gobierna), puramente aleatoriamente conocida si la hipótesis nula fuera cierta? \"\n",
    "\n",
    "---\n",
    "\n",
    "* Esta posibilidad, el valor de probabilidad de observar el estadístico de prueba, es el llamado **valor p (p - value)** y se calcula bajo el supuesto de una cierta distribución de probabilidad (a partir de la cual se genera el estadístico de prueba).\n",
    "\n",
    "* **Nivel de significancia ($\\alpha$)**: se refiere al grado de significancia en el que aceptamos o rechazamos la hipótesis nula. El 100% de precisión no es posible para aceptar o rechazar una hipótesis, por lo que seleccionamos un nivel de 0.05 o 5% (flexible con los datos...), lo que significa que su producción debe tener un 95% de confianza para dar un tipo de resultado similar en cada muestra.\n",
    "\n",
    "![alt text](https://dp8v87cz8a7qa.cloudfront.net/45396/5bd20d03240611540492547.png)\n",
    "\n",
    "---\n",
    "\n",
    "* Error tipo I: cuando rechazamos la hipótesis nula, aunque esa hipótesis era cierta. El error tipo I se denota por alfa. En las pruebas de hipótesis, la curva normal que muestra la región crítica se llama región alfa\n",
    "\n",
    "* Errores de tipo II: cuando aceptamos la hipótesis nula pero es falsa. Los errores de tipo II se denotan por beta. En las pruebas de hipótesis, la curva normal que muestra la región de aceptación se llama región beta.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "* Prueba de una cola: - Una prueba de una hipótesis estadística, donde la región de rechazo está en un solo lado de la distribución de muestreo.\n",
    "\n",
    "Ejemplo: - una universidad tiene ≥ 4000 estudiantes o ciencia de datos ≤ 80% org adoptada.\n",
    "\n",
    "* Prueba de dos colas: una prueba de dos colas es una prueba estadística en la que el área crítica de una distribución es de dos lados y prueba si una muestra es mayor o menor que un cierto rango de valores. Si la muestra que se prueba cae en cualquiera de las áreas críticas, se acepta la hipótesis alternativa en lugar de la hipótesis nula.\n",
    "\n",
    "Ejemplo: una universidad! = 4000 estudiantes o ciencias de datos! = 80% org adoptado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prueba T (t  de Student)\n",
    "\n",
    "Una prueba t es un tipo de estadística inferencial que se utiliza para determinar si existe una diferencia significativa entre las medias de dos grupos que pueden estar relacionadas en ciertas características. \n",
    "\n",
    "Se usa principalmente cuando los conjuntos de datos, como el conjunto de datos registrados como resultado de lanzar una moneda 100 veces, seguirían una distribución normal y pueden tener variaciones desconocidas. La prueba T se usa como una herramienta de prueba de hipótesis, que permite probar un supuesto aplicable a una población.\n",
    "\n",
    "---\n",
    "\n",
    "Nota: Para la comparación de la dispersión se utiliza la prueba Fisher's Test (Comparación de varianzas o desviaciones estandar)\n",
    "\n",
    "---\n",
    "\n",
    "* Prueba t de una muestra: La prueba t de una muestra determina si la media muestral es estadísticamente diferente de una media poblacional conocida o hipotética. La prueba t de una muestra es una **prueba paramétrica**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import ttest_1samp\n",
    "import numpy as np\n",
    "np.random.seed(1984) # para poder replicar el random\n",
    "\n",
    "ages = np.random.randint(50, size=10)\n",
    "print(ages)\n",
    "\n",
    "ages_mean = np.mean(ages)\n",
    "print(ages_mean)\n",
    "\n",
    "tset, pval = ttest_1samp(ages, 30)\n",
    "\n",
    "print(\"tset\",tset)\n",
    "print(\"p-values\",pval)\n",
    "\n",
    "if pval < 0.05:    # alpha value is 0.05 or 5%\n",
    "    print(\" we are rejecting null hypothesis\")\n",
    "else:\n",
    "      print(\"we are accepting null hypothesis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Prueba T de dos muestras: La prueba t de muestras independientes o la prueba t de 2 muestras compara las medias de dos grupos independientes para determinar si existe evidencia estadística de que las medias poblacionales asociadas son significativamente diferentes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import ttest_ind\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(1984) # para poder replicar el random\n",
    "data1 = np.random.randint(50, size=100)\n",
    "data2 = np.random.normal(20, 10, 100)\n",
    "\n",
    "print(\"data1:\")\n",
    "print(data1)\n",
    "print(\"data2:\")\n",
    "print(data2)\n",
    "\n",
    "\n",
    "print(\"data1 mean value:\",np.mean(data1))\n",
    "print(\"data2 mean value:\",np.mean(data2))\n",
    "\n",
    "print(\"data1 std value:\",np.std(data1))\n",
    "print(\"data2 std value:\",np.std(data2))\n",
    "\n",
    "ttest,pval = ttest_ind(data1,data2)\n",
    "\n",
    "print(\"p-value\",pval)\n",
    "if pval <0.05:\n",
    "    print(\"we reject null hypothesis\")\n",
    "else:\n",
    "    print(\"we accept null hypothesis\")\n",
    "    \n",
    "sns.distplot(data1)\n",
    "sns.distplot(data2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ANOVA (F-TEST)\n",
    "\n",
    "La prueba t funciona bien cuando queremos lidiar con 2 grupos, pero en ocasiones necesitamos comparar más de 2 grupos al mismo tiempo.\n",
    "\n",
    "Por ejemplo, si uno desea probar si la edad de los votantes está basado en una variable categórica como la raza, necesitamos comparar las medias de cada uno de los niveles o grupo de la variable.\n",
    "\n",
    "Podríamos aplicar por separado la prueba t para cada grupo de muestras, pero podemos incrementar la probabilidad de tener falsos positivos (Error tipo 1). En análisis de varianza (ANOVA) es una prueba de inferencia estadística que puede ayudar a comparar múltiples grupos al mismo tiempo. \n",
    "\n",
    "![alt text](https://3.bp.blogspot.com/-PDWTzbbwx54/XEbYzExO9rI/AAAAAAAAAAM/AOvAPbXYVUcxmVKnWWrtQaiZ0qhIHo9vwCLcBGAs/s1600/ANOVA.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "404: Not Found\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "  0     0    0     0    0     0      0      0 --:--:--  0:00:01 --:--:--     0curl: (6) Could not resolve host: application\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "100    15  100    15    0     0     77      0 --:--:-- --:--:-- --:--:--    77\n"
     ]
    }
   ],
   "source": [
    "# Fetch the dataset using the raw GitHub URL.\n",
    "!curl --remote-name \\\n",
    "     -H 'Accept: application/vnd.github.v3.raw' \\\n",
    "     --location https://raw.githubusercontent.com/vincentarelbundock/Rdatasets/blob/master/csv/datasets/PlantGrowth.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\"head\" no se reconoce como un comando interno o externo,\n",
      "programa o archivo por lotes ejecutable.\n"
     ]
    }
   ],
   "source": [
    "!head -n 5 PlantGrowth.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-52122e66124b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# leer el dataframe usando read_csv\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"PlantGrowth.csv\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m','\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;31m# mostrar los primeros elementos con head\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "# leer el dataframe usando read_csv\n",
    "df = pd.read_csv(\"PlantGrowth.csv\", sep=',', header=0)\n",
    "# mostrar los primeros elementos con head\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-d12684d8f9b1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'weight'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'group'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mgrps\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0md_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mgrp\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'weight'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroup\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mgrp\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mgrp\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mgrps\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstats\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf_oneway\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0md_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'ctrl'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0md_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'trt1'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0md_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'trt2'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df = df[['weight','group']]\n",
    "grps = pd.unique(df.group.values)\n",
    "d_data = {grp:df['weight'][df.group == grp] for grp in grps}\n",
    " \n",
    "F, p = stats.f_oneway(d_data['ctrl'], d_data['trt1'], d_data['trt2'])\n",
    "\n",
    "print(\"p-value for significance is: \", p)\n",
    "if p<0.05:\n",
    "    print(\"reject null hypothesis\")\n",
    "else:\n",
    "    print(\"accept null hypothesis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "df_anova2 = pd.read_csv(\"https://raw.githubusercontent.com/Opensourcefordatascience/Data-sets/master/crop_yield.csv\")\n",
    "\n",
    "model = ols('Yield ~ C(Fert)*C(Water)', df_anova2).fit()\n",
    "\n",
    "print(f\"Overall model F({model.df_model: .0f},{model.df_resid: .0f}) = {model.fvalue: .3f}, p = {model.f_pvalue: .4f}\")res = sm.stats.anova_lm(model, typ= 2)\n",
    "res"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
