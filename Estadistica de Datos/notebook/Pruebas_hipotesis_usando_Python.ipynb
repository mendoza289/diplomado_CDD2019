{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/jhermosillo/diplomado_CDD2019/blob/master/Estadistica%20de%20Datos/notebook/Pruebas_hipotesis_usando_Python.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.9. Pruebas de hipótesis usando Python\n",
    "---\n",
    "![alt text](https://www.monografias.com/trabajos91/prueba-hipotesis-medias-excel-y-winstats/image002.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bueno, probablemente todos los que somos principiantes o en nivel intermedio en ciencia de datos o los estudiantes de estadística escucharon sobre estas palabras de moda en estas áreas y esto es las prueba de hipótesis.\n",
    "\n",
    "En esta sección se dará una breve introducción sobre este tema que puede causar muchos dolores de cabeza al estar aprendiendo acerca del manejo de datos.\n",
    "\n",
    "Se abordan todos esos conceptos y con ejemplos usando Python.\n",
    "\n",
    "* # ¿Qué es una prueba de hipótesis? \n",
    "* ## ¿Porqué debemos usarlas? \n",
    "* ## ¿Cuáles son las bases de las hipótesis?\n",
    "* ## ¿Cuáles son los parámetros importantes de dichas pruebas?\n",
    "\n",
    "\n",
    "![alt text](https://luminousmen.com/media/demystifying-hypothesis-testing.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Empecemos por la primera pregunta...\n",
    "\n",
    "* ## ¿Qué es una prueba de hipótesis?\n",
    "\n",
    "Las pruebas de hipótesis son métodos estadísticos que son utilizados para la toma de decisiones **estadísticas**, utilizando datos experimentales. En palabras burdas, es el pan de cada día de las estadísticas inferenciales y una habilidad crítica en el repertorio de un científico de datos. Demostramos el concepto con scripts Python muy simples.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ## ¿Porqué usamos las pruebas de hipótesis?\n",
    "\n",
    "La prueba de hipótesis es un procedimiento esencial en estadística. Una prueba de hipótesis evalúa dos afirmaciones mutuamente excluyentes sobre una **población** para determinar qué afirmación es mejor respaldada por los datos de la *muestra*. Cuando decimos que un hallazgo es estadísticamente significativo, es gracias a una prueba de hipótesis.\n",
    "\n",
    "### La prueba de hipótesis es una herramienta crítica en estadística inferencial, para determinar cuál podría ser el valor de un parámetro de **población**. A menudo sacamos esta conclusión basada en un análisis de datos de muestra...."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con la cuestión de la toma de decisiones basada en datos:\n",
    "\n",
    "   * empresariales, científicos, tecnológicos, sociales y políticos, etc... \n",
    "    \n",
    "El concepto de prueba de hipótesis se ha convertido en algo sumamente importante para comprender y aplicar en el contexto adecuado.\n",
    "\n",
    "#### Hay una gran cantidad de pruebas utilizadas en el análisis estadístico para este propósito. Puede ser confuso. Consulte este excelente [artículo](https://towardsdatascience.com/statistical-tests-when-to-use-which-704557554740) para obtener una descripción completa de qué prueba usar en qué situación."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ## ¿Cuales son las bases de las hipótesis? \n",
    "\n",
    "   * ### Hipótesis Nula\n",
    "   * ### Hipótesis Alterna\n",
    "   \n",
    "La hipótesis nula es, en general, lo **aburrido** (esperado), es decir, supone que nada interesante sucede / sucedió.\n",
    "\n",
    "La hipótesis alterna es donde la acción es, es decir, alguna observación / fenómeno es real (es decir, no es una casualidad)...\n",
    "\n",
    "---\n",
    "\n",
    "Hipótesis nula (H0): - En la estadística inferencial, la hipótesis nula es una declaración general o posición predeterminada de que no hay relación entre dos fenómenos medidos, o no hay asociación entre grupos\n",
    "\n",
    "En otras palabras, es una suposición básica o basada en el dominio o el conocimiento del problema.\n",
    "\n",
    "Ejemplo: la producción de una empresa es = 50 unidades / por día, etc.\n",
    "\n",
    "---\n",
    "\n",
    "Hipótesis alterna (H1): - Es la hipótesis contraria a la hipótesis nula. Por lo general, se considera que las observaciones son el resultado de un efecto real (con cierta cantidad de variación de probabilidad superpuesta)\n",
    "\n",
    "Ejemplo: la producción de una empresa es ! = 50 unidades / por día, etc.\n",
    "\n",
    "---\n",
    "## Por lo tanto, el proceso de prueba de hipótesis consiste en formular preguntas sobre los datos en función de la información recopilada y probarlas utilizando métodos estadísticos.\n",
    "\n",
    "---\n",
    "### A continuación mostramos un pequeño ejemplo utilizando la prueba estadística Shapiro - Wilks\n",
    "Esta prueba comprueba si una muestra presenta una distribución normal(H0) o no (H1). Mayor información de la librería pueden consultar el siguiente [artículo](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.shapiro.html) y el [artículo](https://en.wikipedia.org/wiki/Shapiro%E2%80%93Wilk_test) siguiente para la prueba estadística. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of the Shapiro-Wilk Normality Test\n",
    "from scipy.stats import shapiro\n",
    "import seaborn as sns\n",
    "data = [0.873, 2.817, 0.121, -0.945, -0.055, -1.436, 0.360, -1.478, -1.637, -1.869]\n",
    "stat, p = shapiro(data)\n",
    "print('stat=%.3f, p=%.3f' % (stat, p))\n",
    "\n",
    "#El valor crítico de shapiro para n = 10 es  cv = 0.842\n",
    "#El estadistico calculado es stat = 0.895\n",
    "#Aquí podemos ver que stat > cv  <- Aceptamos H1 (Rechazamos H0)\n",
    "\n",
    "#Recordemos este planteamiento. Nuestros datos no son Gaussianos (H0), Nuestos datos son Gaussianos (H1)\n",
    "\n",
    "#Del mismo estadístico tenemos que \"The W statistic needs to be greater than the critical value for the \n",
    "#null hypothesis that the samples are drawn from a Gaussian distribution not to be rejected\"\n",
    "\n",
    "\n",
    "if p > 0.05:\n",
    "    print('Probably Gaussian')\n",
    "else:\n",
    "    print('Probably not Gaussian')\n",
    "    \n",
    "sns.distplot(data)\n",
    "\n",
    "\n",
    "#Lo más recomendable es siempre basarnos en el valor del estadístico calculado (stat)\n",
    "#y tener un conocimiento de los valores críticos\n",
    "\n",
    "#Recordemos lo siguiente de la tabla de confusión\n",
    "\n",
    "#FF <- H0    FV <- Error Tipo 1\n",
    "#VF <- ET2   VV <- H1\n",
    "\n",
    "#Cuando ustedes tienen conocimiento de los estadísticos y los valores críticos\n",
    "\n",
    "#lo ideal es realizar esta comparación para las pruebas de hipótesis\n",
    "# Si STAT <= CV  <- Aceptamos H0 (Rechazamos H1)\n",
    "# Si STAT >  CV  <- Aceptamos H1 (Rechazamos H0)\n",
    "\n",
    "\n",
    "#Caso contrario, les había explicado que podríamos utilizar\n",
    "#la evaluación de el valor de p-value  contra el alpha\n",
    "\n",
    "#Pero al utilizar p-value, las comparaciones pueden ser algo ambigüas, por el simple hecho de\n",
    "#estar ajustandolo para entender la respuesta de las pruebas de hipótesis.\n",
    "\n",
    "#Alpha <- Nivel de Significancia o Nivel de Confianza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilizando random para genera números aleatorios.\n",
    "import numpy as np # importando numpy\n",
    "\n",
    "np.random.seed(1984) # para poder replicar el random\n",
    "from scipy import stats\n",
    "\n",
    "muestras = np.random.normal(0, 1, 50)\n",
    "\n",
    "#muestras = np.random.beta(2, 4, 1000)\n",
    "muestras\n",
    "\n",
    "stat, p = shapiro(muestras)\n",
    "print('stat=%.3f, p=%.3f' % (stat, p))\n",
    "alpha = 0.5\n",
    "if p > alpha:\n",
    "    print('Sample looks Gaussian (fail to reject H0)')\n",
    "else:\n",
    "    print('Sample does not look Gaussian (reject H0)')\n",
    "    \n",
    "sns.distplot(muestras)\n",
    "\n",
    "\n",
    "#En resumen, el p-value tomara la referencia de desigualdad p > a\n",
    "# Si y solo si el estadístico así lo indica\n",
    "# La definición de la prueba de shapiro es que si el estadístico es mayor que el valor crítico\n",
    "# entonces la muestra es gaussiana, aquí estamos trabajando con la hipótesis nula (H0) de que \n",
    "# no \"sabemos\" que tipo de distribución tienen nuestros datos.\n",
    "\n",
    "# Al ser un caso \"especial\", H1 debe ser que los datos presentarán una distribución Normal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A partir de aquí surgen diversas cuestiones extrañas...\n",
    "\n",
    "### ¿Qué son las pruebas estadísticas?\n",
    "* ### ¿Qué es el valor de la prueba (estadística)? \n",
    "\n",
    "    * #### $\\alpha$ (nivel de significancia) \n",
    "    * #### $(p - value)$ \n",
    "    * #### [valor crítico](https://scistatcalc.blogspot.com/2013/09/critical-value-of-w-statistic.html?m=0)\n",
    "    \n",
    "    \n",
    "![alt text](https://iamluminousmen-media.s3.amazonaws.com/media/demystifying-hypothesis-testing/demystifying-hypothesis-testing-3.jpg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.10. Definición de error Tipo I  y  error Tipo II\n",
    "\n",
    "* Error tipo I: cuando rechazamos la hipótesis nula, aunque esa hipótesis era cierta. El error tipo I se denota por alfa. En las pruebas de hipótesis, la curva normal que muestra la región crítica se llama región alfa\n",
    "\n",
    "* Errores de tipo II: cuando aceptamos la hipótesis nula pero es falsa. Los errores de tipo II se denotan por beta. En las pruebas de hipótesis, la curva normal que muestra la región de aceptación se llama región beta.\n",
    "\n",
    "![alt text](https://dp8v87cz8a7qa.cloudfront.net/45396/5bd20d03240611540492547.png)\n",
    "\n",
    "---\n",
    "\n",
    "* Prueba de una cola: - Una prueba de una hipótesis estadística, donde la región de rechazo está en un solo lado de la distribución de muestreo.\n",
    "\n",
    "Ejemplo: - una universidad tiene ≥ 4000 estudiantes o ciencia de datos ≤ 80% org adoptada.\n",
    "\n",
    "* Prueba de dos colas: una prueba de dos colas es una prueba estadística en la que el área crítica de una distribución es de dos lados y prueba si una muestra es mayor o menor que un cierto rango de valores. Si la muestra que se prueba cae en cualquiera de las áreas críticas, se acepta la hipótesis alternativa en lugar de la hipótesis nula.\n",
    "\n",
    "Ejemplo: una universidad! = 4000 estudiantes o ciencias de datos! = 80% org adoptado\n",
    "\n",
    "---\n",
    "\n",
    "### ¿Cuál es el proceso?\n",
    "\n",
    "Normalmente empezamos con un punto de vista simple y empezamos con al hipótesis nula y calculamos (computamos) algunos estadísticos con respecto a nuestras muestras, que se puediera sintetizar de la siguiente manera:\n",
    "\n",
    "### $\\displaystyle\\frac{Mejor estimación − Estimación Hipotética}{Error estandar Estimación}$\n",
    "\n",
    "Donde, la **mejor estimación** proviene de la muestra.. p.ej., la media o algun valor de tendencia central de algún subconjunto de datos de la muestra.\n",
    "\n",
    "El **error estandar** representa la variabilidad en la estimación y depende de la varianza y del tamaño de la muestra.\n",
    "\n",
    "A lo que nos lleva a la siguiente pregunta...\n",
    "\n",
    "### \"¿Cuál es la posibilidad de observar el estadístico de prueba, este extremo, para esta muestra (considerando su tamaño y una dinámica probabilística adecuada que la gobierna), puramente aleatoriamente conocida si la hipótesis nula fuera cierta? \"\n",
    "\n",
    "---\n",
    "## 2.11. Definición de [p-value y alpha](https://blog.minitab.com/blog/adventures-in-statistics-2/understanding-hypothesis-tests-significance-levels-alpha-and-p-values-in-statistics). \n",
    "\n",
    "\n",
    "* Esta posibilidad, el valor de probabilidad de observar el estadístico de prueba, es el llamado **valor p (p - value)** y se calcula bajo el supuesto de una cierta distribución de probabilidad (a partir de la cual se genera el estadístico de prueba).\n",
    "\n",
    "* **Nivel de significancia ($\\alpha$)**: se refiere al grado de significancia en el que aceptamos o rechazamos la hipótesis nula. El 100% de precisión no es posible para aceptar o rechazar una hipótesis, por lo que seleccionamos un nivel de 0.05 o 5% (flexible con los datos...), lo que significa que su producción debe tener un 95% de confianza para dar un tipo de resultado similar en cada muestra.\n",
    "\n",
    "\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pruebas de Hipótesis - Paramétricas\n",
    "\n",
    "### Prueba T (t  de Student)\n",
    "\n",
    "Una prueba t es un tipo de estadística inferencial que se utiliza para determinar si existe una diferencia significativa entre las medias de dos grupos que pueden estar relacionadas en ciertas características. \n",
    "\n",
    "Se usa principalmente cuando los conjuntos de datos, como el conjunto de datos registrados como resultado de lanzar una moneda 100 veces, seguirían una distribución normal y pueden tener variaciones desconocidas. La prueba T se usa como una herramienta de prueba de hipótesis, que permite probar un supuesto aplicable a una población.\n",
    "\n",
    "---\n",
    "\n",
    "Nota: Para la comparación de la dispersión se utiliza la prueba Fisher's Test (Comparación de varianzas o desviaciones estandar)\n",
    "\n",
    "---\n",
    "\n",
    "* Prueba t de una muestra: La prueba t de una muestra determina si la media muestral es estadísticamente diferente de una media poblacional conocida o hipotética. La prueba t de una muestra es una **prueba paramétrica**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import ttest_1samp\n",
    "import numpy as np\n",
    "np.random.seed(1984) # para poder replicar el random\n",
    "\n",
    "ages = np.random.randint(50, size=10)\n",
    "print(ages)\n",
    "\n",
    "ages_mean = np.mean(ages)\n",
    "print(ages_mean)\n",
    "\n",
    "tset, pval = ttest_1samp(ages, 30)\n",
    "\n",
    "print(\"tset\",tset)\n",
    "print(\"p-values\",pval)\n",
    "\n",
    "if pval < 0.05:    # alpha value is 0.05 or 5%\n",
    "    print(\" we are rejecting null hypothesis\")\n",
    "else:\n",
    "      print(\"we are accepting null hypothesis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prueba T de dos muestras\n",
    "\n",
    "* La prueba t de muestras independientes o la prueba t de 2 muestras compara las medias de dos grupos independientes para determinar si existe evidencia estadística de que las medias poblacionales asociadas son significativamente diferentes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import ttest_ind\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(1984) # para poder replicar el random\n",
    "data1 = np.random.randint(50, size=100)\n",
    "data2 = np.random.normal(20, 10, 100)\n",
    "\n",
    "print(\"data1:\")\n",
    "print(data1)\n",
    "print(\"data2:\")\n",
    "print(data2)\n",
    "\n",
    "\n",
    "print(\"data1 mean value:\",np.mean(data1))\n",
    "print(\"data2 mean value:\",np.mean(data2))\n",
    "\n",
    "print(\"data1 std value:\",np.std(data1))\n",
    "print(\"data2 std value:\",np.std(data2))\n",
    "\n",
    "ttest,pval = ttest_ind(data1,data2)\n",
    "\n",
    "print(\"p-value\",pval)\n",
    "if pval <0.05:\n",
    "    print(\"we reject null hypothesis\")\n",
    "else:\n",
    "    print(\"we accept null hypothesis\")\n",
    "    \n",
    "sns.distplot(data1)\n",
    "sns.distplot(data2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ANOVA (F-TEST)\n",
    "\n",
    "La prueba t funciona bien cuando queremos lidiar con 2 grupos, pero en ocasiones necesitamos comparar más de 2 grupos al mismo tiempo.\n",
    "\n",
    "Por ejemplo, si uno desea probar si la edad de los votantes está basado en una variable categórica como la raza, necesitamos comparar las medias de cada uno de los niveles o grupo de la variable.\n",
    "\n",
    "Podríamos aplicar por separado la prueba t para cada grupo de muestras, pero podemos incrementar la probabilidad de tener falsos positivos (Error tipo 1). En análisis de varianza (ANOVA) es una prueba de inferencia estadística que puede ayudar a comparar múltiples grupos al mismo tiempo. \n",
    "\n",
    "![alt text](https://3.bp.blogspot.com/-PDWTzbbwx54/XEbYzExO9rI/AAAAAAAAAAM/AOvAPbXYVUcxmVKnWWrtQaiZ0qhIHo9vwCLcBGAs/s1600/ANOVA.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch the dataset using the raw GitHub URL.\n",
    "!curl --remote-name \\\n",
    "     -H 'Accept: application/vnd.github.v3.raw' \\\n",
    "     --location https://raw.githubusercontent.com/jhermosillo/diplomado_CDD2019/master/Estadistica%20de%20Datos/data/growth.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!head -n 5 PlantGrowth.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# leer el dataframe usando read_csv\n",
    "df = pd.read_csv(\"PlantGrowth.csv\", sep=',', header=0)\n",
    "# mostrar los primeros elementos con head\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['weight','group']]\n",
    "grps = pd.unique(df.group.values)\n",
    "d_data = {grp:df['weight'][df.group == grp] for grp in grps}\n",
    " \n",
    "F, p = stats.f_oneway(d_data['ctrl'], d_data['trt1'], d_data['trt2'])\n",
    "\n",
    "print(\"p-value for significance is: \", p)\n",
    "if p<0.05:\n",
    "    print(\"reject null hypothesis\")\n",
    "else:\n",
    "    print(\"accept null hypothesis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Links de interes - \"Outliers in univariate samples\"\n",
    "* [Critical_Values_Dixon](https://www.researchgate.net/publication/28113620_Critical_values_for_six_Dixon_tests_for_outliers_in_normal_samples_up_to_sizes_100_and_applications_in_science_and_engineering)\n",
    "* [Dixon Test N7 (Q)](http://www.statistics4u.com/fundstat_eng/cc_outlier_tests_dixon.html)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def q_test_for_smallest_point(dataset):\n",
    "    return (dataset[1] - dataset[0])/(dataset[-1] - dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "%matplotlib inline  \n",
    "import seaborn as sns\n",
    "from scipy.stats import norm\n",
    "\n",
    "np.random.seed(1984) # para poder replicar el random\n",
    "data_norm = norm.rvs(size =  50)\n",
    "\n",
    "\n",
    "\n",
    "print(data_norm)\n",
    "alpha = 0.05\n",
    "\n",
    "cv = 0.2216\n",
    "#cv = 0.2960 99% o alpha = 0.01\n",
    "\n",
    "valor_critico = q_test_for_smallest_point(np.sort(data_norm))\n",
    "print(valor_critico)\n",
    "\n",
    "\n",
    "ax = sns.distplot(data_norm, color = 'blue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.distplot(data_norm, color = 'blue')\n",
    "ax.set_title('Distribucion normal')\n",
    "ax.axvline(x = cv, linestyle = '--', label = 'valor critico')\n",
    "ax.axvline(x = valor_critico, linestyle = '--', label = 'valor estadistico', color = 'k')\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Prueba chi-cuadrada\n",
    "\n",
    "La prueba se aplica cuando tiene dos variables categóricas de una sola población. Se utiliza para determinar si existe una asociación significativa entre las dos variables.\n",
    "\n",
    "Por ejemplo, en una encuesta electoral, los votantes pueden clasificarse por género (masculino o femenino) y preferencia de voto (demócrata, republicano o independiente).\n",
    "\n",
    "Sin embargo, los dados son un ejemplo de una variable donde se conoce la \"distribución esperada\". Este no es siempre el caso. A veces, nuestra \"distribución esperada\" se estima a través de los datos.\n",
    "\n",
    "Supongamos por un segundo que no conocemos la frecuencia esperada de tiradas de dado. \n",
    "\n",
    "\n",
    "Tendríamos que estimar la frecuencia esperada a través de muestras de datos. Realicemos algunas muestras para tratar de determinar la frecuencia de cada tirada. \n",
    "\n",
    "Decidí hacer 4 muestras de dados de forma manual (es decir, con dados reales), las primeras 3 muestras fueron de 35 tiradas cada una, y la última muestra de 45 tiradas. Estas son muestras más pequeñas de lo que preferimos, pero quería darnos algunos datos reales para trabajar. Aquí está mi distribución de rollos, con las cuatro muestras denotadas por las letras \"a\", \"b\", \"c\" y \"d\".\n",
    "\n",
    "![alt text](https://miro.medium.com/max/564/1*OB7m3-RUrD5rWP74kDUHcw.jpeg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "a1 = [6, 4, 5, 10]\n",
    "a2 = [8, 5, 3, 3]\n",
    "a3 = [5, 4, 8, 4]\n",
    "a4 = [4, 11, 7, 13]\n",
    "a5 = [5, 8, 7, 6]\n",
    "a6 = [7, 3, 5, 9]\n",
    "\n",
    "dice = np.array([a1, a2, a3, a4, a5, a6])\n",
    "\n",
    "print(dice)\n",
    "from scipy import stats\n",
    "\n",
    "stats.chi2_contingency(dice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chi2_stat, p_val, dof, ex = stats.chi2_contingency(dice)\n",
    "\n",
    "print(\"===Chi2 Stat===\")\n",
    "print(chi2_stat)\n",
    "print(\"\\n\")\n",
    "print(\"===Degrees of Freedom===\")\n",
    "print(dof)\n",
    "print(\"\\n\")\n",
    "print(\"===P-Value===\")\n",
    "print(p_val)\n",
    "print(\"\\n\")\n",
    "print(\"===Contingency Table===\")\n",
    "print(ex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Pruebas de significancia estadística no paramétricas\n",
    "\n",
    "Si los datos no tienen la distribución gaussiana familiar, debemos recurrir a la versión no paramétrica de las pruebas de significancia. Estas pruebas funcionan de manera similar, pero son libres de distribución, lo que requiere que los datos valorados reales se transformen primero en datos de rango antes de que se pueda realizar la prueba.\n",
    "\n",
    "---\n",
    "\n",
    "## Pruebas de Hipótesis -  No Paramétricas\n",
    "\n",
    "En esta sección tenemos la contraparte de las pruebas paramétricas, las cuales son:\n",
    "\n",
    "\n",
    "   * Mann-Whitney U test - Para comparar dos muestras independientes (t de Student)\n",
    "   * Kruskal-Wallis-Friedman tests - Para comparar más de dos muestras (ANOVA)\n",
    "\n",
    "Estas pruebas se usan a menudo en muestras de puntajes de habilidades de modelos para confirmar que la diferencia de habilidades entre los modelos de aprendizaje automático es significativa.\n",
    "\n",
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generamos muestras gaussianas\n",
    "from numpy.random import seed\n",
    "from numpy.random import randn\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "#  # para poder replicar el random\n",
    "seed(1)\n",
    "# generamos dos conjuntos de datos univariados\n",
    "data1 = 5 * randn(100) + 50\n",
    "data2 = 5 * randn(100) + 51\n",
    "# resumen\n",
    "print('data1: mean=%.3f stdv=%.3f' % (mean(data1), std(data1)))\n",
    "print('data2: mean=%.3f stdv=%.3f' % (mean(data2), std(data2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mann-Whitney U Test\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mann-Whitney U test\n",
    "# Generamos muestras gaussianas\n",
    "from numpy.random import seed\n",
    "from numpy.random import randn\n",
    "from scipy.stats import mannwhitneyu\n",
    "#from scipy.stats import ttest_ind\n",
    "import seaborn as sns\n",
    "#  # para poder replicar el random\n",
    "seed(1962)\n",
    "# generamos dos conjuntos de datos univariados\n",
    "data1 = 5 * randn(100) + 50\n",
    "data2 = 5 * randn(100) + 51\n",
    "#  Comparamos muestras\n",
    "stat, p = mannwhitneyu(data1, data2)\n",
    "\n",
    "#ttest,pval = ttest_ind(data1,data2)\n",
    "\n",
    "print('Statistics=%.3f, p=%.3f' % (stat, p))\n",
    "\n",
    "#print('Statistics=%.3f, p=%.3f' % (ttest, pval))\n",
    "\n",
    "# interpretamos\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "\tprint('Misma distribución (H0)')\n",
    "else:\n",
    "\tprint('Distribución diferente (H1)')\n",
    "    \n",
    "sns.distplot(data1)\n",
    "sns.distplot(data2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kruskal-Wallis H Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kruskal-Wallis H-test\n",
    "from numpy.random import seed\n",
    "from numpy.random import randn\n",
    "from scipy.stats import kruskal\n",
    "import seaborn as sns\n",
    "#  # para poder replicar el random\n",
    "seed(1962)\n",
    "# generate three independent samples\n",
    "data1 = 5 * randn(100) + 50\n",
    "data2 = 5 * randn(100) + 50\n",
    "data3 = 5 * randn(100) + 52\n",
    "# comparacion\n",
    "stat, p = kruskal(data1, data2, data3)\n",
    "print('Statistics=%.3f, p=%.3f' % (stat, p))\n",
    "# interpretacion\n",
    "alpha = 0.05\n",
    "if p > alpha:\n",
    "\tprint('Misma Distribucion (H0)')\n",
    "else:\n",
    "\tprint('Distribución diferente (H1)')\n",
    "    \n",
    "sns.distplot(data1)\n",
    "sns.distplot(data2)\n",
    "sns.distplot(data3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
